{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YXvFsJZv5C8z",
        "outputId": "e2a88315-f92d-4fcd-81b9-203594a288b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (8.1.7)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.2)\n",
            "Requirement already satisfied: pyspng in /usr/local/lib/python3.10/dist-packages (0.1.1)\n",
            "Requirement already satisfied: ninja in /usr/local/lib/python3.10/dist-packages (1.11.1.1)\n",
            "Requirement already satisfied: imageio-ffmpeg in /usr/local/lib/python3.10/dist-packages (0.4.9)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2024.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from pyspng) (1.25.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from imageio-ffmpeg) (67.7.2)\n",
            "PyTorch version: 2.2.1+cu121\n",
            "CUDA device: NVIDIA A100-SXM4-40GB\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "!pip install click requests tqdm pyspng ninja imageio-ffmpeg\n",
        "\n",
        "print(\"PyTorch version:\", torch.__version__)\n",
        "print(\"CUDA device:\", torch.cuda.get_device_name(device=None))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G34AQ33_GhwK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4ce769f-c656-420a-b1fe-8cbc0aeee90a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BUKY2XCRTtE-",
        "outputId": "12ca98de-c45b-414e-a7b1-7c5d927d5c08"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.10.12 (main, Nov 20 2023, 15:14:05) [GCC 11.4.0]\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "print(sys.version)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ojCYfEAHOv29",
        "outputId": "f060b2a8-eaee-4b7b-b928-7f37e7bfc0ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Numpy versionL 1.25.2\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "print(\"Numpy versionL\",np.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C1cJ0WMoUGy4",
        "outputId": "94c80f85-f7bc-4ea8-b904-c75d9b3bae20"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "scipy  1.11.4\n"
          ]
        }
      ],
      "source": [
        "import scipy\n",
        "print(\"scipy \",scipy.__version__)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i-6EWPOCHvVa",
        "outputId": "ddd9830f-e394-465e-d92a-5b5d4ebd6394"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (67.7.2)\n"
          ]
        }
      ],
      "source": [
        "# !pip uninstall torch\n",
        "# !pip uninstall torch\n",
        "# !pip install torch==1.10.0+cu113 torchvision==0.11.1+cu113 torchaudio===0.10.0+cu113 -f https://download.pytorch.org/whl/cu113/torch_stable.html\n",
        "# !python --version  # Check Python version need 3.8>\n",
        "# !pip install torch==1.11.0 torchvision   # need torch > 1.9.0\n",
        "# !nvcc --version  # Check CUDA version\n",
        "# !pip install setuptools"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uUcURpT9e0tp",
        "outputId": "d181bb2e-8c29-4274-9148-2fa7bb838de9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (8.1.7)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.31.0)\n",
            "Requirement already satisfied: pyspng in /usr/local/lib/python3.10/dist-packages (0.1.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.2)\n",
            "Requirement already satisfied: pyopengl in /usr/local/lib/python3.10/dist-packages (3.1.7)\n",
            "Requirement already satisfied: ninja in /usr/local/lib/python3.10/dist-packages (1.11.1.1)\n",
            "Requirement already satisfied: imageio-ffmpeg in /usr/local/lib/python3.10/dist-packages (0.4.9)\n",
            "Collecting imgui\n",
            "  Downloading imgui-2.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m42.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2024.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from pyspng) (1.25.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from imageio-ffmpeg) (67.7.2)\n",
            "Installing collected packages: imgui\n",
            "Successfully installed imgui-2.0.0\n",
            "12.1\n",
            "2.2.1+cu121\n",
            "NVIDIA A100-SXM4-40GB\n"
          ]
        }
      ],
      "source": [
        "import fnmatch\n",
        "import os\n",
        "from os import listdir,makedirs\n",
        "from os.path import isfile,join\n",
        "\n",
        "!pip install click requests pyspng tqdm pyopengl ninja imageio-ffmpeg imgui\n",
        "\n",
        "print(torch.version.cuda)\n",
        "print(torch.__version__)\n",
        "print(torch.cuda.get_device_name(device=None))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X9WUBNo9PEpP"
      },
      "source": [
        "# Creat environment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7tF3Z3isO9Gh"
      },
      "source": [
        "# Data preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aJWzGamP9KZ4"
      },
      "source": [
        "**Prepare training dataset**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H_xvOf4fBub1"
      },
      "source": [
        "Preprocess test dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gp_R3cN0Gdkg",
        "outputId": "93606e9f-4836-40d8-9b91-cac922bc3679"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100% 4041/4041 [10:26<00:00,  6.45it/s]\n"
          ]
        }
      ],
      "source": [
        "!python /content/drive/MyDrive/stylegan3_test/stylegan3/dataset_tool.py --source=/content/drive/MyDrive/csc_496FinalProject/Data/Landshapes-4041 --dest=/content/drive/MyDrive/csc_496FinalProject/Data/Landshapes-4041.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rwDhLcr2CB12"
      },
      "source": [
        "# Start Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9pgtvJk2CBJM",
        "outputId": "25daa4fe-5dbe-481a-bf99-9776d6750905"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training options:\n",
            "{\n",
            "  \"G_kwargs\": {\n",
            "    \"class_name\": \"training.networks_stylegan3.Generator\",\n",
            "    \"z_dim\": 512,\n",
            "    \"w_dim\": 512,\n",
            "    \"mapping_kwargs\": {\n",
            "      \"num_layers\": 2\n",
            "    },\n",
            "    \"channel_base\": 32768,\n",
            "    \"channel_max\": 512,\n",
            "    \"magnitude_ema_beta\": 0.9988915792636801\n",
            "  },\n",
            "  \"D_kwargs\": {\n",
            "    \"class_name\": \"training.networks_stylegan2.Discriminator\",\n",
            "    \"block_kwargs\": {\n",
            "      \"freeze_layers\": 0\n",
            "    },\n",
            "    \"mapping_kwargs\": {},\n",
            "    \"epilogue_kwargs\": {\n",
            "      \"mbstd_group_size\": 4\n",
            "    },\n",
            "    \"channel_base\": 32768,\n",
            "    \"channel_max\": 512\n",
            "  },\n",
            "  \"G_opt_kwargs\": {\n",
            "    \"class_name\": \"torch.optim.Adam\",\n",
            "    \"betas\": [\n",
            "      0,\n",
            "      0.99\n",
            "    ],\n",
            "    \"eps\": 1e-08,\n",
            "    \"lr\": 0.0025\n",
            "  },\n",
            "  \"D_opt_kwargs\": {\n",
            "    \"class_name\": \"torch.optim.Adam\",\n",
            "    \"betas\": [\n",
            "      0,\n",
            "      0.99\n",
            "    ],\n",
            "    \"eps\": 1e-08,\n",
            "    \"lr\": 0.002\n",
            "  },\n",
            "  \"loss_kwargs\": {\n",
            "    \"class_name\": \"training.loss.StyleGAN2Loss\",\n",
            "    \"r1_gamma\": 32.0\n",
            "  },\n",
            "  \"data_loader_kwargs\": {\n",
            "    \"pin_memory\": true,\n",
            "    \"prefetch_factor\": 2,\n",
            "    \"num_workers\": 3\n",
            "  },\n",
            "  \"training_set_kwargs\": {\n",
            "    \"class_name\": \"training.dataset.ImageFolderDataset\",\n",
            "    \"path\": \"/content/drive/MyDrive/csc_496FinalProject/Data/Landshapes-4041.zip\",\n",
            "    \"use_labels\": false,\n",
            "    \"max_size\": 4041,\n",
            "    \"xflip\": true,\n",
            "    \"resolution\": 1024,\n",
            "    \"random_seed\": 0\n",
            "  },\n",
            "  \"num_gpus\": 1,\n",
            "  \"batch_size\": 32,\n",
            "  \"batch_gpu\": 4,\n",
            "  \"metrics\": [],\n",
            "  \"total_kimg\": 1000,\n",
            "  \"kimg_per_tick\": 4,\n",
            "  \"image_snapshot_ticks\": 5,\n",
            "  \"network_snapshot_ticks\": 5,\n",
            "  \"random_seed\": 0,\n",
            "  \"ema_kimg\": 10.0,\n",
            "  \"augment_kwargs\": {\n",
            "    \"class_name\": \"training.augment.AugmentPipe\",\n",
            "    \"xflip\": 1,\n",
            "    \"rotate90\": 1,\n",
            "    \"xint\": 1,\n",
            "    \"scale\": 1,\n",
            "    \"rotate\": 1,\n",
            "    \"aniso\": 1,\n",
            "    \"xfrac\": 1,\n",
            "    \"brightness\": 1,\n",
            "    \"contrast\": 1,\n",
            "    \"lumaflip\": 1,\n",
            "    \"hue\": 1,\n",
            "    \"saturation\": 1\n",
            "  },\n",
            "  \"ada_target\": 0.6,\n",
            "  \"run_dir\": \"/content/drive/MyDrive/csc_496FinalProject/StyleGAN_train_landshapes/training_runs/00000-stylegan3-t-Landshapes-4041-gpus1-batch32-gamma32\"\n",
            "}\n",
            "\n",
            "Output directory:    /content/drive/MyDrive/csc_496FinalProject/StyleGAN_train_landshapes/training_runs/00000-stylegan3-t-Landshapes-4041-gpus1-batch32-gamma32\n",
            "Number of GPUs:      1\n",
            "Batch size:          32 images\n",
            "Training duration:   1000 kimg\n",
            "Dataset path:        /content/drive/MyDrive/csc_496FinalProject/Data/Landshapes-4041.zip\n",
            "Dataset size:        4041 images\n",
            "Dataset resolution:  1024\n",
            "Dataset labels:      False\n",
            "Dataset x-flips:     True\n",
            "\n",
            "Creating output directory...\n",
            "Launching processes...\n",
            "Loading training set...\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/sampler.py:64: UserWarning: `data_source` argument is not used and will be removed in 2.2.0.You may still have custom implementation that utilizes it.\n",
            "  warnings.warn(\"`data_source` argument is not used and will be removed in 2.2.0.\"\n",
            "\n",
            "Num images:  8082\n",
            "Image shape: [3, 1024, 1024]\n",
            "Label shape: [0]\n",
            "\n",
            "Constructing networks...\n",
            "Setting up PyTorch plugin \"bias_act_plugin\"... Done.\n",
            "Setting up PyTorch plugin \"filtered_lrelu_plugin\"... Done.\n",
            "\n",
            "Generator                     Parameters  Buffers  Output shape         Datatype\n",
            "---                           ---         ---      ---                  ---     \n",
            "mapping.fc0                   262656      -        [4, 512]             float32 \n",
            "mapping.fc1                   262656      -        [4, 512]             float32 \n",
            "mapping                       -           512      [4, 16, 512]         float32 \n",
            "synthesis.input.affine        2052        -        [4, 4]               float32 \n",
            "synthesis.input               262144      1545     [4, 512, 36, 36]     float32 \n",
            "synthesis.L0_36_512.affine    262656      -        [4, 512]             float32 \n",
            "synthesis.L0_36_512           2359808     25       [4, 512, 36, 36]     float32 \n",
            "synthesis.L1_36_512.affine    262656      -        [4, 512]             float32 \n",
            "synthesis.L1_36_512           2359808     25       [4, 512, 36, 36]     float32 \n",
            "synthesis.L2_52_512.affine    262656      -        [4, 512]             float32 \n",
            "synthesis.L2_52_512           2359808     37       [4, 512, 52, 52]     float32 \n",
            "synthesis.L3_52_512.affine    262656      -        [4, 512]             float32 \n",
            "synthesis.L3_52_512           2359808     25       [4, 512, 52, 52]     float32 \n",
            "synthesis.L4_84_512.affine    262656      -        [4, 512]             float32 \n",
            "synthesis.L4_84_512           2359808     37       [4, 512, 84, 84]     float32 \n",
            "synthesis.L5_148_512.affine   262656      -        [4, 512]             float32 \n",
            "synthesis.L5_148_512          2359808     37       [4, 512, 148, 148]   float16 \n",
            "synthesis.L6_148_512.affine   262656      -        [4, 512]             float32 \n",
            "synthesis.L6_148_512          2359808     25       [4, 512, 148, 148]   float16 \n",
            "synthesis.L7_276_323.affine   262656      -        [4, 512]             float32 \n",
            "synthesis.L7_276_323          1488707     37       [4, 323, 276, 276]   float16 \n",
            "synthesis.L8_276_203.affine   165699      -        [4, 323]             float32 \n",
            "synthesis.L8_276_203          590324      25       [4, 203, 276, 276]   float16 \n",
            "synthesis.L9_532_128.affine   104139      -        [4, 203]             float32 \n",
            "synthesis.L9_532_128          233984      37       [4, 128, 532, 532]   float16 \n",
            "synthesis.L10_1044_81.affine  65664       -        [4, 128]             float32 \n",
            "synthesis.L10_1044_81         93393       37       [4, 81, 1044, 1044]  float16 \n",
            "synthesis.L11_1044_51.affine  41553       -        [4, 81]              float32 \n",
            "synthesis.L11_1044_51         37230       25       [4, 51, 1044, 1044]  float16 \n",
            "synthesis.L12_1044_32.affine  26163       -        [4, 51]              float32 \n",
            "synthesis.L12_1044_32         14720       25       [4, 32, 1044, 1044]  float16 \n",
            "synthesis.L13_1024_32.affine  16416       -        [4, 32]              float32 \n",
            "synthesis.L13_1024_32         9248        25       [4, 32, 1024, 1024]  float16 \n",
            "synthesis.L14_1024_3.affine   16416       -        [4, 32]              float32 \n",
            "synthesis.L14_1024_3          99          1        [4, 3, 1024, 1024]   float16 \n",
            "synthesis                     -           -        [4, 3, 1024, 1024]   float32 \n",
            "---                           ---         ---      ---                  ---     \n",
            "Total                         22313167    2480     -                    -       \n",
            "\n",
            "Setting up PyTorch plugin \"upfirdn2d_plugin\"... Done.\n",
            "\n",
            "Discriminator  Parameters  Buffers  Output shape         Datatype\n",
            "---            ---         ---      ---                  ---     \n",
            "b1024.fromrgb  128         16       [4, 32, 1024, 1024]  float16 \n",
            "b1024.skip     2048        16       [4, 64, 512, 512]    float16 \n",
            "b1024.conv0    9248        16       [4, 32, 1024, 1024]  float16 \n",
            "b1024.conv1    18496       16       [4, 64, 512, 512]    float16 \n",
            "b1024          -           16       [4, 64, 512, 512]    float16 \n",
            "b512.skip      8192        16       [4, 128, 256, 256]   float16 \n",
            "b512.conv0     36928       16       [4, 64, 512, 512]    float16 \n",
            "b512.conv1     73856       16       [4, 128, 256, 256]   float16 \n",
            "b512           -           16       [4, 128, 256, 256]   float16 \n",
            "b256.skip      32768       16       [4, 256, 128, 128]   float16 \n",
            "b256.conv0     147584      16       [4, 128, 256, 256]   float16 \n",
            "b256.conv1     295168      16       [4, 256, 128, 128]   float16 \n",
            "b256           -           16       [4, 256, 128, 128]   float16 \n",
            "b128.skip      131072      16       [4, 512, 64, 64]     float16 \n",
            "b128.conv0     590080      16       [4, 256, 128, 128]   float16 \n",
            "b128.conv1     1180160     16       [4, 512, 64, 64]     float16 \n",
            "b128           -           16       [4, 512, 64, 64]     float16 \n",
            "b64.skip       262144      16       [4, 512, 32, 32]     float32 \n",
            "b64.conv0      2359808     16       [4, 512, 64, 64]     float32 \n",
            "b64.conv1      2359808     16       [4, 512, 32, 32]     float32 \n",
            "b64            -           16       [4, 512, 32, 32]     float32 \n",
            "b32.skip       262144      16       [4, 512, 16, 16]     float32 \n",
            "b32.conv0      2359808     16       [4, 512, 32, 32]     float32 \n",
            "b32.conv1      2359808     16       [4, 512, 16, 16]     float32 \n",
            "b32            -           16       [4, 512, 16, 16]     float32 \n",
            "b16.skip       262144      16       [4, 512, 8, 8]       float32 \n",
            "b16.conv0      2359808     16       [4, 512, 16, 16]     float32 \n",
            "b16.conv1      2359808     16       [4, 512, 8, 8]       float32 \n",
            "b16            -           16       [4, 512, 8, 8]       float32 \n",
            "b8.skip        262144      16       [4, 512, 4, 4]       float32 \n",
            "b8.conv0       2359808     16       [4, 512, 8, 8]       float32 \n",
            "b8.conv1       2359808     16       [4, 512, 4, 4]       float32 \n",
            "b8             -           16       [4, 512, 4, 4]       float32 \n",
            "b4.mbstd       -           -        [4, 513, 4, 4]       float32 \n",
            "b4.conv        2364416     16       [4, 512, 4, 4]       float32 \n",
            "b4.fc          4194816     -        [4, 512]             float32 \n",
            "b4.out         513         -        [4, 1]               float32 \n",
            "---            ---         ---      ---                  ---     \n",
            "Total          29012513    544      -                    -       \n",
            "\n",
            "Setting up augmentation...\n",
            "Distributing across 1 GPUs...\n",
            "Setting up training phases...\n",
            "Exporting sample images...\n",
            "Initializing logs...\n",
            "2024-05-05 04:24:28.314137: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-05-05 04:24:28.314203: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-05-05 04:24:28.316193: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-05-05 04:24:29.354254: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Training for 1000 kimg...\n",
            "\n",
            "tick 0     kimg 0.0      time 3m 56s       sec/tick 60.4    sec/kimg 1886.17 maintenance 175.7  cpumem 3.37   gpumem 36.69  reserved 38.80  augment 0.000\n",
            "tick 1     kimg 4.0      time 12m 45s      sec/tick 522.7   sec/kimg 130.66  maintenance 6.7    cpumem 3.88   gpumem 9.01   reserved 11.25  augment 0.003\n",
            "tick 2     kimg 8.0      time 21m 37s      sec/tick 531.3   sec/kimg 132.82  maintenance 0.0    cpumem 3.88   gpumem 9.00   reserved 11.25  augment 0.005\n",
            "tick 3     kimg 12.0     time 30m 28s      sec/tick 531.3   sec/kimg 132.82  maintenance 0.0    cpumem 3.88   gpumem 8.87   reserved 11.25  augment 0.006\n",
            "tick 4     kimg 16.0     time 39m 20s      sec/tick 531.5   sec/kimg 132.87  maintenance 0.0    cpumem 3.88   gpumem 9.01   reserved 11.25  augment 0.007\n",
            "tick 5     kimg 20.0     time 48m 11s      sec/tick 531.6   sec/kimg 132.89  maintenance 0.0    cpumem 3.88   gpumem 9.01   reserved 11.25  augment 0.008\n",
            "tick 6     kimg 24.0     time 56m 58s      sec/tick 523.0   sec/kimg 130.74  maintenance 3.9    cpumem 3.86   gpumem 9.01   reserved 11.25  augment 0.012\n",
            "tick 7     kimg 28.0     time 1h 05m 50s   sec/tick 531.6   sec/kimg 132.90  maintenance 0.0    cpumem 3.86   gpumem 8.91   reserved 11.25  augment 0.016\n",
            "tick 8     kimg 32.0     time 1h 14m 41s   sec/tick 531.1   sec/kimg 132.76  maintenance 0.0    cpumem 3.86   gpumem 8.91   reserved 11.25  augment 0.019\n",
            "tick 9     kimg 36.0     time 1h 23m 33s   sec/tick 531.8   sec/kimg 132.95  maintenance 0.0    cpumem 3.86   gpumem 9.00   reserved 11.25  augment 0.026\n",
            "tick 10    kimg 40.0     time 1h 32m 24s   sec/tick 531.1   sec/kimg 132.77  maintenance 0.0    cpumem 3.86   gpumem 9.00   reserved 11.25  augment 0.029\n",
            "tick 11    kimg 44.0     time 1h 41m 10s   sec/tick 522.8   sec/kimg 130.69  maintenance 3.9    cpumem 3.86   gpumem 8.99   reserved 11.25  augment 0.034\n",
            "tick 12    kimg 48.0     time 1h 50m 02s   sec/tick 531.3   sec/kimg 132.82  maintenance 0.0    cpumem 3.86   gpumem 9.01   reserved 11.25  augment 0.040\n",
            "tick 13    kimg 52.0     time 1h 58m 53s   sec/tick 531.5   sec/kimg 132.88  maintenance 0.0    cpumem 3.86   gpumem 9.01   reserved 11.25  augment 0.048\n",
            "tick 14    kimg 56.0     time 2h 07m 45s   sec/tick 531.6   sec/kimg 132.91  maintenance 0.0    cpumem 3.86   gpumem 9.02   reserved 11.25  augment 0.055\n",
            "tick 15    kimg 60.0     time 2h 16m 37s   sec/tick 531.9   sec/kimg 132.96  maintenance 0.0    cpumem 3.86   gpumem 9.04   reserved 11.25  augment 0.061\n",
            "tick 16    kimg 64.0     time 2h 25m 32s   sec/tick 531.3   sec/kimg 132.83  maintenance 3.6    cpumem 3.86   gpumem 9.20   reserved 11.25  augment 0.069\n",
            "tick 17    kimg 68.0     time 2h 34m 17s   sec/tick 524.2   sec/kimg 131.05  maintenance 1.0    cpumem 3.86   gpumem 9.05   reserved 11.25  augment 0.076\n",
            "tick 18    kimg 72.0     time 2h 43m 09s   sec/tick 532.1   sec/kimg 133.03  maintenance 0.0    cpumem 3.86   gpumem 9.01   reserved 11.25  augment 0.083\n",
            "tick 19    kimg 76.0     time 2h 52m 01s   sec/tick 532.2   sec/kimg 133.06  maintenance 0.0    cpumem 3.86   gpumem 9.07   reserved 11.26  augment 0.091\n",
            "tick 20    kimg 80.0     time 3h 00m 54s   sec/tick 532.4   sec/kimg 133.09  maintenance 0.0    cpumem 3.86   gpumem 9.06   reserved 11.26  augment 0.098\n",
            "tick 21    kimg 84.0     time 3h 09m 51s   sec/tick 533.3   sec/kimg 133.33  maintenance 3.6    cpumem 3.86   gpumem 9.03   reserved 11.26  augment 0.105\n",
            "tick 22    kimg 88.0     time 3h 18m 35s   sec/tick 524.5   sec/kimg 131.12  maintenance 0.0    cpumem 3.86   gpumem 9.02   reserved 11.26  augment 0.112\n"
          ]
        }
      ],
      "source": [
        "# !python train.py --outdir=/content/drive/MyDrive/StyleGAN2-multidomain/soap/training-runs1 \\\n",
        "#  --gpus=1 --mirror=1 --snap=5 --aug=ada \\\n",
        "#  --data=/content/drive/MyDrive/stylegan2-ada-pytorch/datasets/soap_8k_1024res.zip \\\n",
        "#  --cfg=stylegan2_gpu1 \\\n",
        "#  --kimg=1000 \\\n",
        "#  --metrics=none\n",
        "# !python /content/drive/MyDrive/stylegan3/train.py --outdir=/content/drive/MyDrive/stylegan3_results \\\n",
        "#  --data=/content/drive/MyDrive/stylegan3_test/output/output_dataset.zip \\\n",
        "#  --gpus=1 --cfg=auto --batch=32 --gamma=6.6 \\\n",
        "#  --mirror=1 --kimg=500 --snap=5\n",
        "\n",
        "\n",
        "!python /content/drive/MyDrive/styleGAN3_19th_Century_Landscape/stylegan3/train.py --outdir=/content/drive/MyDrive/csc_496FinalProject/StyleGAN_train_landshapes/training_runs \\\n",
        "--cfg=stylegan3-t \\\n",
        "--data=/content/drive/MyDrive/csc_496FinalProject/Data/Landshapes-4041.zip \\\n",
        "--gpus=1 --kimg=1000 --aug=ada --batch=32 --gamma=32 --batch-gpu=4 \\\n",
        "--mirror=1 --snap=5 --metrics=none"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_VcMG8iOf2qp",
        "outputId": "d45292ce-582e-43f1-a62a-614580372aca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/stylegan3_test\n"
          ]
        }
      ],
      "source": [
        "%cd /content/drive/MyDrive/stylegan3_test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cwhGDQCf-rRF"
      },
      "source": [
        "## Resume Training with slightly modified dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ma7NSfRr-ptn",
        "outputId": "e53aca4e-ea7a-4616-be25-b815c2926b6a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "100% 1424/1424 [01:07<00:00, 21.06it/s]\n"
          ]
        }
      ],
      "source": [
        "!python /content/drive/MyDrive/stylegan3_test/stylegan3/dataset_tool.py --source=/content/drive/MyDrive/stylegan3_test/19th_Century_French_Updated --dest=/content/drive/MyDrive/stylegan3_test/output/output_dataset.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UCGx02Lk-pwt"
      },
      "outputs": [],
      "source": [
        "batch_size = 32\n",
        "batch_gpu_size = 8\n",
        "# /content/drive/MyDrive/stylegan3_train/19th_Century_French/19th_Century_French_Training_Run-1\n",
        "dataset_path = '/content/drive/MyDrive/stylegan3_train/19th_Century_French/output/19th_Century_French_Scaled1024.zip'\n",
        "# resume_from =' /content/drive/MyDrive/fine_tune_stylegan3wikiart/wikiart-1024-stylegan3-t-17.2Mimg.pkl'\n",
        "resume_from = '/content/drive/MyDrive/stylegan3_train/19th_Century_French/19th_Century_French_Training_Run-1/00001-stylegan3-t-19th_Century_French_Scaled1024-gpus1-batch32-gamma32/network-snapshot-000520.pkl'\n",
        "snapshot_count = 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZCrsIJPe-p1K",
        "outputId": "8ee9790d-4056-4102-a6aa-54fb2c433c48"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training options:\n",
            "{\n",
            "  \"G_kwargs\": {\n",
            "    \"class_name\": \"training.networks_stylegan3.Generator\",\n",
            "    \"z_dim\": 512,\n",
            "    \"w_dim\": 512,\n",
            "    \"mapping_kwargs\": {\n",
            "      \"num_layers\": 2\n",
            "    },\n",
            "    \"channel_base\": 32768,\n",
            "    \"channel_max\": 512,\n",
            "    \"magnitude_ema_beta\": 0.9988915792636801\n",
            "  },\n",
            "  \"D_kwargs\": {\n",
            "    \"class_name\": \"training.networks_stylegan2.Discriminator\",\n",
            "    \"block_kwargs\": {\n",
            "      \"freeze_layers\": 0\n",
            "    },\n",
            "    \"mapping_kwargs\": {},\n",
            "    \"epilogue_kwargs\": {\n",
            "      \"mbstd_group_size\": 4\n",
            "    },\n",
            "    \"channel_base\": 32768,\n",
            "    \"channel_max\": 512\n",
            "  },\n",
            "  \"G_opt_kwargs\": {\n",
            "    \"class_name\": \"torch.optim.Adam\",\n",
            "    \"betas\": [\n",
            "      0,\n",
            "      0.99\n",
            "    ],\n",
            "    \"eps\": 1e-08,\n",
            "    \"lr\": 0.0025\n",
            "  },\n",
            "  \"D_opt_kwargs\": {\n",
            "    \"class_name\": \"torch.optim.Adam\",\n",
            "    \"betas\": [\n",
            "      0,\n",
            "      0.99\n",
            "    ],\n",
            "    \"eps\": 1e-08,\n",
            "    \"lr\": 0.002\n",
            "  },\n",
            "  \"loss_kwargs\": {\n",
            "    \"class_name\": \"training.loss.StyleGAN2Loss\",\n",
            "    \"r1_gamma\": 32.0,\n",
            "    \"blur_init_sigma\": 0\n",
            "  },\n",
            "  \"data_loader_kwargs\": {\n",
            "    \"pin_memory\": true,\n",
            "    \"prefetch_factor\": 2,\n",
            "    \"num_workers\": 3\n",
            "  },\n",
            "  \"training_set_kwargs\": {\n",
            "    \"class_name\": \"training.dataset.ImageFolderDataset\",\n",
            "    \"path\": \"/content/drive/MyDrive/stylegan3_train/19th_Century_French/output/19th_Century_French_Scaled1024.zip\",\n",
            "    \"use_labels\": false,\n",
            "    \"max_size\": 1382,\n",
            "    \"xflip\": false,\n",
            "    \"resolution\": 1024,\n",
            "    \"random_seed\": 0\n",
            "  },\n",
            "  \"num_gpus\": 1,\n",
            "  \"batch_size\": 32,\n",
            "  \"batch_gpu\": 4,\n",
            "  \"metrics\": [],\n",
            "  \"total_kimg\": 1000,\n",
            "  \"kimg_per_tick\": 4,\n",
            "  \"image_snapshot_ticks\": 5,\n",
            "  \"network_snapshot_ticks\": 5,\n",
            "  \"random_seed\": 0,\n",
            "  \"ema_kimg\": 10.0,\n",
            "  \"augment_kwargs\": {\n",
            "    \"class_name\": \"training.augment.AugmentPipe\",\n",
            "    \"xflip\": 1,\n",
            "    \"rotate90\": 1,\n",
            "    \"xint\": 1,\n",
            "    \"scale\": 1,\n",
            "    \"rotate\": 1,\n",
            "    \"aniso\": 1,\n",
            "    \"xfrac\": 1,\n",
            "    \"brightness\": 1,\n",
            "    \"contrast\": 1,\n",
            "    \"lumaflip\": 1,\n",
            "    \"hue\": 1,\n",
            "    \"saturation\": 1\n",
            "  },\n",
            "  \"ada_target\": 0.6,\n",
            "  \"resume_pkl\": \"/content/drive/MyDrive/stylegan3_train/19th_Century_French/19th_Century_French_Training_Run-1/00001-stylegan3-t-19th_Century_French_Scaled1024-gpus1-batch32-gamma32/network-snapshot-000520.pkl\",\n",
            "  \"ada_kimg\": 100,\n",
            "  \"ema_rampup\": null,\n",
            "  \"run_dir\": \"/content/drive/MyDrive/stylegan3_train/19th_Century_French/19th_Century_French_Training_Run-1/00002-stylegan3-t-19th_Century_French_Scaled1024-gpus1-batch32-gamma32\"\n",
            "}\n",
            "\n",
            "Output directory:    /content/drive/MyDrive/stylegan3_train/19th_Century_French/19th_Century_French_Training_Run-1/00002-stylegan3-t-19th_Century_French_Scaled1024-gpus1-batch32-gamma32\n",
            "Number of GPUs:      1\n",
            "Batch size:          32 images\n",
            "Training duration:   1000 kimg\n",
            "Dataset path:        /content/drive/MyDrive/stylegan3_train/19th_Century_French/output/19th_Century_French_Scaled1024.zip\n",
            "Dataset size:        1382 images\n",
            "Dataset resolution:  1024\n",
            "Dataset labels:      False\n",
            "Dataset x-flips:     False\n",
            "\n",
            "Creating output directory...\n",
            "Launching processes...\n",
            "Loading training set...\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/sampler.py:64: UserWarning: `data_source` argument is not used and will be removed in 2.2.0.You may still have custom implementation that utilizes it.\n",
            "  warnings.warn(\"`data_source` argument is not used and will be removed in 2.2.0.\"\n",
            "\n",
            "Num images:  1382\n",
            "Image shape: [3, 1024, 1024]\n",
            "Label shape: [0]\n",
            "\n",
            "Constructing networks...\n",
            "Resuming from \"/content/drive/MyDrive/stylegan3_train/19th_Century_French/19th_Century_French_Training_Run-1/00001-stylegan3-t-19th_Century_French_Scaled1024-gpus1-batch32-gamma32/network-snapshot-000520.pkl\"\n",
            "Setting up PyTorch plugin \"bias_act_plugin\"... Done.\n",
            "Setting up PyTorch plugin \"filtered_lrelu_plugin\"... Done.\n",
            "\n",
            "Generator                     Parameters  Buffers  Output shape         Datatype\n",
            "---                           ---         ---      ---                  ---     \n",
            "mapping.fc0                   262656      -        [4, 512]             float32 \n",
            "mapping.fc1                   262656      -        [4, 512]             float32 \n",
            "mapping                       -           512      [4, 16, 512]         float32 \n",
            "synthesis.input.affine        2052        -        [4, 4]               float32 \n",
            "synthesis.input               262144      1545     [4, 512, 36, 36]     float32 \n",
            "synthesis.L0_36_512.affine    262656      -        [4, 512]             float32 \n",
            "synthesis.L0_36_512           2359808     25       [4, 512, 36, 36]     float32 \n",
            "synthesis.L1_36_512.affine    262656      -        [4, 512]             float32 \n",
            "synthesis.L1_36_512           2359808     25       [4, 512, 36, 36]     float32 \n",
            "synthesis.L2_52_512.affine    262656      -        [4, 512]             float32 \n",
            "synthesis.L2_52_512           2359808     37       [4, 512, 52, 52]     float32 \n",
            "synthesis.L3_52_512.affine    262656      -        [4, 512]             float32 \n",
            "synthesis.L3_52_512           2359808     25       [4, 512, 52, 52]     float32 \n",
            "synthesis.L4_84_512.affine    262656      -        [4, 512]             float32 \n",
            "synthesis.L4_84_512           2359808     37       [4, 512, 84, 84]     float32 \n",
            "synthesis.L5_148_512.affine   262656      -        [4, 512]             float32 \n",
            "synthesis.L5_148_512          2359808     37       [4, 512, 148, 148]   float16 \n",
            "synthesis.L6_148_512.affine   262656      -        [4, 512]             float32 \n",
            "synthesis.L6_148_512          2359808     25       [4, 512, 148, 148]   float16 \n",
            "synthesis.L7_276_323.affine   262656      -        [4, 512]             float32 \n",
            "synthesis.L7_276_323          1488707     37       [4, 323, 276, 276]   float16 \n",
            "synthesis.L8_276_203.affine   165699      -        [4, 323]             float32 \n",
            "synthesis.L8_276_203          590324      25       [4, 203, 276, 276]   float16 \n",
            "synthesis.L9_532_128.affine   104139      -        [4, 203]             float32 \n",
            "synthesis.L9_532_128          233984      37       [4, 128, 532, 532]   float16 \n",
            "synthesis.L10_1044_81.affine  65664       -        [4, 128]             float32 \n",
            "synthesis.L10_1044_81         93393       37       [4, 81, 1044, 1044]  float16 \n",
            "synthesis.L11_1044_51.affine  41553       -        [4, 81]              float32 \n",
            "synthesis.L11_1044_51         37230       25       [4, 51, 1044, 1044]  float16 \n",
            "synthesis.L12_1044_32.affine  26163       -        [4, 51]              float32 \n",
            "synthesis.L12_1044_32         14720       25       [4, 32, 1044, 1044]  float16 \n",
            "synthesis.L13_1024_32.affine  16416       -        [4, 32]              float32 \n",
            "synthesis.L13_1024_32         9248        25       [4, 32, 1024, 1024]  float16 \n",
            "synthesis.L14_1024_3.affine   16416       -        [4, 32]              float32 \n",
            "synthesis.L14_1024_3          99          1        [4, 3, 1024, 1024]   float16 \n",
            "synthesis                     -           -        [4, 3, 1024, 1024]   float32 \n",
            "---                           ---         ---      ---                  ---     \n",
            "Total                         22313167    2480     -                    -       \n",
            "\n",
            "Setting up PyTorch plugin \"upfirdn2d_plugin\"... Done.\n",
            "\n",
            "Discriminator  Parameters  Buffers  Output shape         Datatype\n",
            "---            ---         ---      ---                  ---     \n",
            "b1024.fromrgb  128         16       [4, 32, 1024, 1024]  float16 \n",
            "b1024.skip     2048        16       [4, 64, 512, 512]    float16 \n",
            "b1024.conv0    9248        16       [4, 32, 1024, 1024]  float16 \n",
            "b1024.conv1    18496       16       [4, 64, 512, 512]    float16 \n",
            "b1024          -           16       [4, 64, 512, 512]    float16 \n",
            "b512.skip      8192        16       [4, 128, 256, 256]   float16 \n",
            "b512.conv0     36928       16       [4, 64, 512, 512]    float16 \n",
            "b512.conv1     73856       16       [4, 128, 256, 256]   float16 \n",
            "b512           -           16       [4, 128, 256, 256]   float16 \n",
            "b256.skip      32768       16       [4, 256, 128, 128]   float16 \n",
            "b256.conv0     147584      16       [4, 128, 256, 256]   float16 \n",
            "b256.conv1     295168      16       [4, 256, 128, 128]   float16 \n",
            "b256           -           16       [4, 256, 128, 128]   float16 \n",
            "b128.skip      131072      16       [4, 512, 64, 64]     float16 \n",
            "b128.conv0     590080      16       [4, 256, 128, 128]   float16 \n",
            "b128.conv1     1180160     16       [4, 512, 64, 64]     float16 \n",
            "b128           -           16       [4, 512, 64, 64]     float16 \n",
            "b64.skip       262144      16       [4, 512, 32, 32]     float32 \n",
            "b64.conv0      2359808     16       [4, 512, 64, 64]     float32 \n",
            "b64.conv1      2359808     16       [4, 512, 32, 32]     float32 \n",
            "b64            -           16       [4, 512, 32, 32]     float32 \n",
            "b32.skip       262144      16       [4, 512, 16, 16]     float32 \n",
            "b32.conv0      2359808     16       [4, 512, 32, 32]     float32 \n",
            "b32.conv1      2359808     16       [4, 512, 16, 16]     float32 \n",
            "b32            -           16       [4, 512, 16, 16]     float32 \n",
            "b16.skip       262144      16       [4, 512, 8, 8]       float32 \n",
            "b16.conv0      2359808     16       [4, 512, 16, 16]     float32 \n",
            "b16.conv1      2359808     16       [4, 512, 8, 8]       float32 \n",
            "b16            -           16       [4, 512, 8, 8]       float32 \n",
            "b8.skip        262144      16       [4, 512, 4, 4]       float32 \n",
            "b8.conv0       2359808     16       [4, 512, 8, 8]       float32 \n",
            "b8.conv1       2359808     16       [4, 512, 4, 4]       float32 \n",
            "b8             -           16       [4, 512, 4, 4]       float32 \n",
            "b4.mbstd       -           -        [4, 513, 4, 4]       float32 \n",
            "b4.conv        2364416     16       [4, 512, 4, 4]       float32 \n",
            "b4.fc          4194816     -        [4, 512]             float32 \n",
            "b4.out         513         -        [4, 1]               float32 \n",
            "---            ---         ---      ---                  ---     \n",
            "Total          29012513    544      -                    -       \n",
            "\n",
            "Setting up augmentation...\n",
            "Distributing across 1 GPUs...\n",
            "Setting up training phases...\n",
            "Exporting sample images...\n",
            "Initializing logs...\n",
            "2024-03-26 03:20:48.622166: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-03-26 03:20:48.622228: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-03-26 03:20:48.624146: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-03-26 03:20:49.654955: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Training for 1000 kimg...\n",
            "\n",
            "tick 0     kimg 0.0      time 3m 54s       sec/tick 60.2    sec/kimg 1879.80 maintenance 174.2  cpumem 3.69   gpumem 36.69  reserved 38.80  augment 0.000\n",
            "tick 1     kimg 4.0      time 12m 54s      sec/tick 522.4   sec/kimg 130.59  maintenance 17.1   cpumem 4.22   gpumem 9.01   reserved 10.50  augment 0.029\n",
            "tick 2     kimg 8.0      time 21m 45s      sec/tick 531.3   sec/kimg 132.82  maintenance 0.0    cpumem 4.22   gpumem 9.13   reserved 10.50  augment 0.059\n",
            "tick 3     kimg 12.0     time 30m 37s      sec/tick 531.9   sec/kimg 132.97  maintenance 0.0    cpumem 4.23   gpumem 9.02   reserved 10.50  augment 0.079\n",
            "tick 4     kimg 16.0     time 39m 30s      sec/tick 532.7   sec/kimg 133.16  maintenance 0.0    cpumem 4.23   gpumem 9.02   reserved 10.50  augment 0.070\n",
            "tick 5     kimg 20.0     time 48m 21s      sec/tick 531.6   sec/kimg 132.90  maintenance 0.0    cpumem 4.23   gpumem 9.03   reserved 10.50  augment 0.061\n",
            "tick 6     kimg 24.0     time 57m 21s      sec/tick 523.3   sec/kimg 130.82  maintenance 15.8   cpumem 4.23   gpumem 9.01   reserved 10.50  augment 0.073\n",
            "tick 7     kimg 28.0     time 1h 06m 13s   sec/tick 532.2   sec/kimg 133.06  maintenance 0.0    cpumem 4.23   gpumem 9.04   reserved 10.50  augment 0.083\n",
            "tick 8     kimg 32.0     time 1h 15m 05s   sec/tick 532.0   sec/kimg 133.00  maintenance 0.0    cpumem 4.23   gpumem 9.02   reserved 10.50  augment 0.086\n",
            "\n",
            "Aborted!\n"
          ]
        }
      ],
      "source": [
        "!python /content/drive/MyDrive/stylegan3_test/stylegan3/train.py --outdir=/content/drive/MyDrive/stylegan3_train/19th_Century_French/19th_Century_French_Training_Run-1 \\\n",
        "--cfg=stylegan3-t \\\n",
        "--data=$dataset_path --gpus=1 --batch=32 --batch-gpu=4 --gamma=32 --kimg=1000 \\\n",
        "--snap=$snapshot_count --resume=$resume_from --metrics=none"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Koxwn-rNZXrc"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zUrrWpUPZYb6"
      },
      "source": [
        "##Fine tune wikiart1024"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I6wfhbbTlm_B",
        "outputId": "ee0417b3-8702-4a80-ae7c-90ff2895cb06"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2023 NVIDIA Corporation\n",
            "Built on Tue_Aug_15_22:02:13_PDT_2023\n",
            "Cuda compilation tools, release 12.2, V12.2.140\n",
            "Build cuda_12.2.r12.2/compiler.33191640_0\n"
          ]
        }
      ],
      "source": [
        "!nvcc --version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D4sMglc6mPEK",
        "outputId": "6061795a-1e71-42f7-bf44-4cbcc738ab9d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found existing installation: torch 2.1.0+cu121\n",
            "Uninstalling torch-2.1.0+cu121:\n",
            "  Successfully uninstalled torch-2.1.0+cu121\n"
          ]
        }
      ],
      "source": [
        "!pip uninstall torch -y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "125EGcE_lf5n",
        "outputId": "15c7548f-4ee9-403b-fae7-3be2d1c186be"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting torch\n",
            "  Downloading torch-2.2.1-cp310-cp310-manylinux1_x86_64.whl (755.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m755.5/755.5 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (2.1.0+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.16.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.10.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m64.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m65.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m88.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m29.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu12==2.19.3 (from torch)\n",
            "  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch)\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting triton==2.2.0 (from torch)\n",
            "  Downloading triton-2.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (167.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.9/167.9 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.99-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m81.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch\n",
            "  Downloading torch-2.1.0-cp310-cp310-manylinux1_x86_64.whl (670.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m670.2/670.2 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu12==2.18.1 (from torch)\n",
            "  Downloading nvidia_nccl_cu12-2.18.1-py3-none-manylinux1_x86_64.whl (209.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.8/209.8 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.25.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.31.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.18.1 nvidia-nvjitlink-cu12-12.4.99 nvidia-nvtx-cu12-12.1.105 torch-2.1.0\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "id": "c77964869cff451194be2eb15ed9eac9",
              "pip_warning": {
                "packages": [
                  "torch",
                  "torchgen"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "!pip install torch torchaudio torchvision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rbbpWKQtrKyo",
        "outputId": "065cdbe7-e547-405b-f0a7-d7b579089515"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/fine_tune_stylegan3wikiart/stylegan3/torch_utils/ops\n"
          ]
        }
      ],
      "source": [
        "%cd /content/drive/MyDrive/fine_tune_stylegan3wikiart/stylegan3/torch_utils/ops"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nN_nIv_7rPbN",
        "outputId": "1786a021-3840-422d-ac26-5d3f229080e0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "total 200\n",
            "-rw------- 1 root root  4389 Mar  5 22:46 bias_act.cpp\n",
            "-rw------- 1 root root  6160 Mar  5 22:46 bias_act.cu\n",
            "-rw------- 1 root root  1293 Mar  5 22:46 bias_act.h\n",
            "-rw------- 1 root root  9813 Mar  5 22:46 bias_act.py\n",
            "-rw------- 1 root root  9465 Mar  5 22:46 conv2d_gradfix.py\n",
            "-rw------- 1 root root  6765 Mar  5 22:46 conv2d_resample.py\n",
            "-rw------- 1 root root 15597 Mar  5 22:46 filtered_lrelu.cpp\n",
            "-rw------- 1 root root 67307 Mar  5 22:46 filtered_lrelu.cu\n",
            "-rw------- 1 root root  4448 Mar  5 22:46 filtered_lrelu.h\n",
            "-rw------- 1 root root  1638 Mar  5 22:46 filtered_lrelu_ns.cu\n",
            "-rw------- 1 root root 12884 Mar  5 22:46 filtered_lrelu.py\n",
            "-rw------- 1 root root  1607 Mar  5 22:46 filtered_lrelu_rd.cu\n",
            "-rw------- 1 root root  1608 Mar  5 22:46 filtered_lrelu_wr.cu\n",
            "-rw------- 1 root root  2047 Mar  5 22:46 fma.py\n",
            "-rw------- 1 root root  3020 Mar  5 22:46 grid_sample_gradfix.py\n",
            "-rw------- 1 root root   448 Mar  5 22:46 __init__.py\n",
            "drwx------ 2 root root  4096 Mar  5 23:41 \u001b[0m\u001b[01;34m__pycache__\u001b[0m/\n",
            "-rw------- 1 root root  5027 Mar  5 22:46 upfirdn2d.cpp\n",
            "-rw------- 1 root root 23137 Mar  5 22:46 upfirdn2d.cu\n",
            "-rw------- 1 root root  1849 Mar  5 22:46 upfirdn2d.h\n",
            "-rw------- 1 root root 16392 Mar  5 22:46 upfirdn2d.py\n"
          ]
        }
      ],
      "source": [
        "%ls -l"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RVTsrNOBsVNt"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TAdPhs6Xrdw-"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3DKh1Efk-p4E"
      },
      "outputs": [],
      "source": [
        "batch_size = 16\n",
        "batch_gpu_size = 8\n",
        "\n",
        "dataset_path = '/content/drive/MyDrive/fine_tune_stylegan3wikiart/output/output_dataset.zip'\n",
        "resume_from ='/content/drive/MyDrive/fine_tune_stylegan3wikiart/wikiart-1024-stylegan3-t-17.2Mimg.pkl'\n",
        "\n",
        "\n",
        "gamma_value = 8\n",
        "snapshot_count = 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bf56viZX-p64",
        "outputId": "c40bf962-8aac-4881-9936-920c20ac2098"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Training options:\n",
            "{\n",
            "  \"G_kwargs\": {\n",
            "    \"class_name\": \"training.networks_stylegan3.Generator\",\n",
            "    \"z_dim\": 512,\n",
            "    \"w_dim\": 512,\n",
            "    \"mapping_kwargs\": {\n",
            "      \"num_layers\": 2\n",
            "    },\n",
            "    \"channel_base\": 32768,\n",
            "    \"channel_max\": 512,\n",
            "    \"magnitude_ema_beta\": 0.9994456359721023\n",
            "  },\n",
            "  \"D_kwargs\": {\n",
            "    \"class_name\": \"training.networks_stylegan2.Discriminator\",\n",
            "    \"block_kwargs\": {\n",
            "      \"freeze_layers\": 0\n",
            "    },\n",
            "    \"mapping_kwargs\": {},\n",
            "    \"epilogue_kwargs\": {\n",
            "      \"mbstd_group_size\": 4\n",
            "    },\n",
            "    \"channel_base\": 32768,\n",
            "    \"channel_max\": 512\n",
            "  },\n",
            "  \"G_opt_kwargs\": {\n",
            "    \"class_name\": \"torch.optim.Adam\",\n",
            "    \"betas\": [\n",
            "      0,\n",
            "      0.99\n",
            "    ],\n",
            "    \"eps\": 1e-08,\n",
            "    \"lr\": 0.0025\n",
            "  },\n",
            "  \"D_opt_kwargs\": {\n",
            "    \"class_name\": \"torch.optim.Adam\",\n",
            "    \"betas\": [\n",
            "      0,\n",
            "      0.99\n",
            "    ],\n",
            "    \"eps\": 1e-08,\n",
            "    \"lr\": 0.002\n",
            "  },\n",
            "  \"loss_kwargs\": {\n",
            "    \"class_name\": \"training.loss.StyleGAN2Loss\",\n",
            "    \"r1_gamma\": 8.0,\n",
            "    \"blur_init_sigma\": 0\n",
            "  },\n",
            "  \"data_loader_kwargs\": {\n",
            "    \"pin_memory\": true,\n",
            "    \"prefetch_factor\": 2,\n",
            "    \"num_workers\": 3\n",
            "  },\n",
            "  \"training_set_kwargs\": {\n",
            "    \"class_name\": \"training.dataset.ImageFolderDataset\",\n",
            "    \"path\": \"/content/drive/MyDrive/fine_tune_stylegan3wikiart/output/output_dataset.zip\",\n",
            "    \"use_labels\": false,\n",
            "    \"max_size\": 1445,\n",
            "    \"xflip\": false,\n",
            "    \"resolution\": 1024,\n",
            "    \"random_seed\": 0\n",
            "  },\n",
            "  \"num_gpus\": 1,\n",
            "  \"batch_size\": 16,\n",
            "  \"batch_gpu\": 8,\n",
            "  \"metrics\": [\n",
            "    \"fid50k_full\"\n",
            "  ],\n",
            "  \"total_kimg\": 1000,\n",
            "  \"kimg_per_tick\": 4,\n",
            "  \"image_snapshot_ticks\": 5,\n",
            "  \"network_snapshot_ticks\": 5,\n",
            "  \"random_seed\": 0,\n",
            "  \"ema_kimg\": 5.0,\n",
            "  \"augment_kwargs\": {\n",
            "    \"class_name\": \"training.augment.AugmentPipe\",\n",
            "    \"xflip\": 1,\n",
            "    \"rotate90\": 1,\n",
            "    \"xint\": 1,\n",
            "    \"scale\": 1,\n",
            "    \"rotate\": 1,\n",
            "    \"aniso\": 1,\n",
            "    \"xfrac\": 1,\n",
            "    \"brightness\": 1,\n",
            "    \"contrast\": 1,\n",
            "    \"lumaflip\": 1,\n",
            "    \"hue\": 1,\n",
            "    \"saturation\": 1\n",
            "  },\n",
            "  \"ada_target\": 0.6,\n",
            "  \"resume_pkl\": \"/content/drive/MyDrive/fine_tune_stylegan3wikiart/wikiart-1024-stylegan3-t-17.2Mimg.pkl\",\n",
            "  \"ada_kimg\": 100,\n",
            "  \"ema_rampup\": null,\n",
            "  \"run_dir\": \"/content/drive/MyDrive/fine_tune_stylegan3wikiart/19th_Century_French_Fine_Tune1/00009-stylegan3-t-output_dataset-gpus1-batch16-gamma8\"\n",
            "}\n",
            "\n",
            "Output directory:    /content/drive/MyDrive/fine_tune_stylegan3wikiart/19th_Century_French_Fine_Tune1/00009-stylegan3-t-output_dataset-gpus1-batch16-gamma8\n",
            "Number of GPUs:      1\n",
            "Batch size:          16 images\n",
            "Training duration:   1000 kimg\n",
            "Dataset path:        /content/drive/MyDrive/fine_tune_stylegan3wikiart/output/output_dataset.zip\n",
            "Dataset size:        1445 images\n",
            "Dataset resolution:  1024\n",
            "Dataset labels:      False\n",
            "Dataset x-flips:     False\n",
            "\n",
            "Creating output directory...\n",
            "Launching processes...\n",
            "Loading training set...\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/sampler.py:64: UserWarning: `data_source` argument is not used and will be removed in 2.2.0.You may still have custom implementation that utilizes it.\n",
            "  warnings.warn(\"`data_source` argument is not used and will be removed in 2.2.0.\"\n",
            "\n",
            "Num images:  1445\n",
            "Image shape: [3, 1024, 1024]\n",
            "Label shape: [0]\n",
            "\n",
            "Constructing networks...\n",
            "Resuming from \"/content/drive/MyDrive/fine_tune_stylegan3wikiart/wikiart-1024-stylegan3-t-17.2Mimg.pkl\"\n",
            "Setting up PyTorch plugin \"bias_act_plugin\"... Done.\n",
            "Setting up PyTorch plugin \"filtered_lrelu_plugin\"... Done.\n",
            "\n",
            "Generator                     Parameters  Buffers  Output shape         Datatype\n",
            "---                           ---         ---      ---                  ---     \n",
            "mapping.fc0                   262656      -        [8, 512]             float32 \n",
            "mapping.fc1                   262656      -        [8, 512]             float32 \n",
            "mapping                       -           512      [8, 16, 512]         float32 \n",
            "synthesis.input.affine        2052        -        [8, 4]               float32 \n",
            "synthesis.input               262144      1545     [8, 512, 36, 36]     float32 \n",
            "synthesis.L0_36_512.affine    262656      -        [8, 512]             float32 \n",
            "synthesis.L0_36_512           2359808     25       [8, 512, 36, 36]     float32 \n",
            "synthesis.L1_36_512.affine    262656      -        [8, 512]             float32 \n",
            "synthesis.L1_36_512           2359808     25       [8, 512, 36, 36]     float32 \n",
            "synthesis.L2_52_512.affine    262656      -        [8, 512]             float32 \n",
            "synthesis.L2_52_512           2359808     37       [8, 512, 52, 52]     float32 \n",
            "synthesis.L3_52_512.affine    262656      -        [8, 512]             float32 \n",
            "synthesis.L3_52_512           2359808     25       [8, 512, 52, 52]     float32 \n",
            "synthesis.L4_84_512.affine    262656      -        [8, 512]             float32 \n",
            "synthesis.L4_84_512           2359808     37       [8, 512, 84, 84]     float32 \n",
            "synthesis.L5_148_512.affine   262656      -        [8, 512]             float32 \n",
            "synthesis.L5_148_512          2359808     37       [8, 512, 148, 148]   float16 \n",
            "synthesis.L6_148_512.affine   262656      -        [8, 512]             float32 \n",
            "synthesis.L6_148_512          2359808     25       [8, 512, 148, 148]   float16 \n",
            "synthesis.L7_276_323.affine   262656      -        [8, 512]             float32 \n",
            "synthesis.L7_276_323          1488707     37       [8, 323, 276, 276]   float16 \n",
            "synthesis.L8_276_203.affine   165699      -        [8, 323]             float32 \n",
            "synthesis.L8_276_203          590324      25       [8, 203, 276, 276]   float16 \n",
            "synthesis.L9_532_128.affine   104139      -        [8, 203]             float32 \n",
            "synthesis.L9_532_128          233984      37       [8, 128, 532, 532]   float16 \n",
            "synthesis.L10_1044_81.affine  65664       -        [8, 128]             float32 \n",
            "synthesis.L10_1044_81         93393       37       [8, 81, 1044, 1044]  float16 \n",
            "synthesis.L11_1044_51.affine  41553       -        [8, 81]              float32 \n",
            "synthesis.L11_1044_51         37230       25       [8, 51, 1044, 1044]  float16 \n",
            "synthesis.L12_1044_32.affine  26163       -        [8, 51]              float32 \n",
            "synthesis.L12_1044_32         14720       25       [8, 32, 1044, 1044]  float16 \n",
            "synthesis.L13_1024_32.affine  16416       -        [8, 32]              float32 \n",
            "synthesis.L13_1024_32         9248        25       [8, 32, 1024, 1024]  float16 \n",
            "synthesis.L14_1024_3.affine   16416       -        [8, 32]              float32 \n",
            "synthesis.L14_1024_3          99          1        [8, 3, 1024, 1024]   float16 \n",
            "synthesis                     -           -        [8, 3, 1024, 1024]   float32 \n",
            "---                           ---         ---      ---                  ---     \n",
            "Total                         22313167    2480     -                    -       \n",
            "\n",
            "Setting up PyTorch plugin \"upfirdn2d_plugin\"... Done.\n",
            "\n",
            "Discriminator  Parameters  Buffers  Output shape         Datatype\n",
            "---            ---         ---      ---                  ---     \n",
            "b1024.fromrgb  128         16       [8, 32, 1024, 1024]  float16 \n",
            "b1024.skip     2048        16       [8, 64, 512, 512]    float16 \n",
            "b1024.conv0    9248        16       [8, 32, 1024, 1024]  float16 \n",
            "b1024.conv1    18496       16       [8, 64, 512, 512]    float16 \n",
            "b1024          -           16       [8, 64, 512, 512]    float16 \n",
            "b512.skip      8192        16       [8, 128, 256, 256]   float16 \n",
            "b512.conv0     36928       16       [8, 64, 512, 512]    float16 \n",
            "b512.conv1     73856       16       [8, 128, 256, 256]   float16 \n",
            "b512           -           16       [8, 128, 256, 256]   float16 \n",
            "b256.skip      32768       16       [8, 256, 128, 128]   float16 \n",
            "b256.conv0     147584      16       [8, 128, 256, 256]   float16 \n",
            "b256.conv1     295168      16       [8, 256, 128, 128]   float16 \n",
            "b256           -           16       [8, 256, 128, 128]   float16 \n",
            "b128.skip      131072      16       [8, 512, 64, 64]     float16 \n",
            "b128.conv0     590080      16       [8, 256, 128, 128]   float16 \n",
            "b128.conv1     1180160     16       [8, 512, 64, 64]     float16 \n",
            "b128           -           16       [8, 512, 64, 64]     float16 \n",
            "b64.skip       262144      16       [8, 512, 32, 32]     float32 \n",
            "b64.conv0      2359808     16       [8, 512, 64, 64]     float32 \n",
            "b64.conv1      2359808     16       [8, 512, 32, 32]     float32 \n",
            "b64            -           16       [8, 512, 32, 32]     float32 \n",
            "b32.skip       262144      16       [8, 512, 16, 16]     float32 \n",
            "b32.conv0      2359808     16       [8, 512, 32, 32]     float32 \n",
            "b32.conv1      2359808     16       [8, 512, 16, 16]     float32 \n",
            "b32            -           16       [8, 512, 16, 16]     float32 \n",
            "b16.skip       262144      16       [8, 512, 8, 8]       float32 \n",
            "b16.conv0      2359808     16       [8, 512, 16, 16]     float32 \n",
            "b16.conv1      2359808     16       [8, 512, 8, 8]       float32 \n",
            "b16            -           16       [8, 512, 8, 8]       float32 \n",
            "b8.skip        262144      16       [8, 512, 4, 4]       float32 \n",
            "b8.conv0       2359808     16       [8, 512, 8, 8]       float32 \n",
            "b8.conv1       2359808     16       [8, 512, 4, 4]       float32 \n",
            "b8             -           16       [8, 512, 4, 4]       float32 \n",
            "b4.mbstd       -           -        [8, 513, 4, 4]       float32 \n",
            "b4.conv        2364416     16       [8, 512, 4, 4]       float32 \n",
            "b4.fc          4194816     -        [8, 512]             float32 \n",
            "b4.out         513         -        [8, 1]               float32 \n",
            "---            ---         ---      ---                  ---     \n",
            "Total          29012513    544      -                    -       \n",
            "\n",
            "Setting up augmentation...\n",
            "Distributing across 1 GPUs...\n",
            "Setting up training phases...\n",
            "Exporting sample images...\n",
            "Initializing logs...\n",
            "2024-03-07 05:35:05.826845: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-03-07 05:35:05.826902: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-03-07 05:35:05.828270: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-03-07 05:35:06.784510: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Training for 1000 kimg...\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/fine_tune_stylegan3wikiart/stylegan3/train.py\", line 286, in <module>\n",
            "    main() # pylint: disable=no-value-for-parameter\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/click/core.py\", line 1157, in __call__\n",
            "    return self.main(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/click/core.py\", line 1078, in main\n",
            "    rv = self.invoke(ctx)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/click/core.py\", line 1434, in invoke\n",
            "    return ctx.invoke(self.callback, **ctx.params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/click/core.py\", line 783, in invoke\n",
            "    return __callback(*args, **kwargs)\n",
            "  File \"/content/drive/MyDrive/fine_tune_stylegan3wikiart/stylegan3/train.py\", line 281, in main\n",
            "    launch_training(c=c, desc=desc, outdir=opts.outdir, dry_run=opts.dry_run)\n",
            "  File \"/content/drive/MyDrive/fine_tune_stylegan3wikiart/stylegan3/train.py\", line 96, in launch_training\n",
            "    subprocess_fn(rank=0, c=c, temp_dir=temp_dir)\n",
            "  File \"/content/drive/MyDrive/fine_tune_stylegan3wikiart/stylegan3/train.py\", line 47, in subprocess_fn\n",
            "    training_loop.training_loop(rank=rank, **c)\n",
            "  File \"/content/drive/MyDrive/fine_tune_stylegan3wikiart/stylegan3/training/training_loop.py\", line 278, in training_loop\n",
            "    loss.accumulate_gradients(phase=phase.name, real_img=real_img, real_c=real_c, gen_z=gen_z, gen_c=gen_c, gain=phase.interval, cur_nimg=cur_nimg)\n",
            "  File \"/content/drive/MyDrive/fine_tune_stylegan3wikiart/stylegan3/training/loss.py\", line 81, in accumulate_gradients\n",
            "    loss_Gmain.mean().mul(gain).backward()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\", line 492, in backward\n",
            "    torch.autograd.backward(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\", line 251, in backward\n",
            "    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/autograd/function.py\", line 288, in apply\n",
            "    return user_fn(self, *args)\n",
            "  File \"/content/drive/MyDrive/fine_tune_stylegan3wikiart/stylegan3/torch_utils/ops/grid_sample_gradfix.py\", line 50, in backward\n",
            "    grad_input, grad_grid = _GridSample2dBackward.apply(grad_output, input, grid)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/autograd/function.py\", line 539, in apply\n",
            "    return super().apply(*args, **kwargs)  # type: ignore[misc]\n",
            "  File \"/content/drive/MyDrive/fine_tune_stylegan3wikiart/stylegan3/torch_utils/ops/grid_sample_gradfix.py\", line 59, in forward\n",
            "    grad_input, grad_grid = op(grad_output, input, grid, 0, 0, False)\n",
            "TypeError: 'tuple' object is not callable\n"
          ]
        }
      ],
      "source": [
        "!python /content/drive/MyDrive/fine_tune_stylegan3wikiart/stylegan3/train.py --outdir=/content/drive/MyDrive/fine_tune_stylegan3wikiart/19th_Century_French_Fine_Tune1 --cfg=stylegan3-t \\\n",
        "--data=$dataset_path --gpus=1 --batch=$batch_size --batch-gpu=$batch_gpu_size --gamma=$gamma_value --kimg=1000 \\\n",
        "--snap=$snapshot_count --resume=$resume_from"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4rs0M-jsJutZ"
      },
      "outputs": [],
      "source": [
        "!which ninja"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "53mrneUw7KsG",
        "outputId": "18ba1238-65ac-401b-a207-8e2bda2260dd"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/opt/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/tools/node/bin:/tools/google-cloud-sdk/bin'"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "os.environ['PATH']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IdIsyQ247iym",
        "outputId": "56d6d3fb-ae17-407d-922e-227f86d40c87"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/opt/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/tools/node/bin:/tools/google-cloud-sdk/bin:/usr/local/bin/ninja\n"
          ]
        }
      ],
      "source": [
        "os.environ['PATH'] = os.environ['PATH'] + \":/usr/local/bin/ninja\"\n",
        "print(os.environ['PATH'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "-gik1gdX9ECJ",
        "outputId": "7375f30a-d30c-48ae-b89e-49bd5bd96784"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/opt/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/tools/node/bin:/tools/google-cloud-sdk/bin:/usr/local/bin/ninja'"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "A = \"/opt/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/tools/node/bin:/tools/google-cloud-sdk/bin\"\n",
        "A + \":/usr/local/bin/ninja\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BaroXadJ979U",
        "outputId": "deed0d42-0d40-4a7f-ee86-a7f5d8b8087d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import subprocess\n",
        "def is_ninja_available():\n",
        "    r'''\n",
        "    Returns ``True`` if the `ninja <https://ninja-build.org/>`_ build system is\n",
        "    available on the system, ``False`` otherwise.\n",
        "    '''\n",
        "    try:\n",
        "        subprocess.check_output('ninja --version'.split())\n",
        "    except Exception:\n",
        "        return False\n",
        "    else:\n",
        "        return True\n",
        "\n",
        "is_ninja_available()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}